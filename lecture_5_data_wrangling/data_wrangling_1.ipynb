{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "artificial-filling",
   "metadata": {},
   "source": [
    "# Data Wrangling: Input/Output\n",
    "\n",
    "In this lecture/notebook, we'll look at the following:\n",
    "* Different data file types used in Astronomy/Astrophysics\n",
    "* Ways of opening data files and accessing the data within Python\n",
    "* Ways of saving data from a Python session to a file\n",
    "* Best Practices for dealing with files\n",
    "\n",
    "For this lesson, we're going to be using the following packages:\n",
    "* `numpy`\n",
    "* `pandas`\n",
    "* `astropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy import table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-disease",
   "metadata": {},
   "source": [
    "## Data Types we deal with in Astronomy\n",
    "\n",
    "In astronomy (and in much coding), there's a variety of different file formats that you'll deal with data in:\n",
    "* Plain, Unstructured Text \n",
    "* Structured Plain Text (most commonly, Comma-Separated Values or `csv`)\n",
    "* Numpy files (`.npy` or `.npz`)\n",
    "* FITS files<sup>a</sup>\n",
    "* Structured Markdown (such as HTML)\n",
    "\n",
    "---\n",
    "1: We won't go into FITS files in detail. What you _should_ know about them in a nutshell: they contain groups of data, most often images (which are just 2D or 3D arrays of numbers, usually floating points), or tables of data. The tables are relatively easy to read-in with `astropy` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-african",
   "metadata": {},
   "source": [
    "## The most basic of file writing: a plain unstructured text file\n",
    "* Opening the file\n",
    "* Reading all of the content within the file\n",
    "* The file as a string\n",
    "* Writing out a file\n",
    "* Closing a file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-brazilian",
   "metadata": {},
   "source": [
    "#### Reading a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open(\"input.txt\", 'r')\n",
    "\n",
    "type(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = input_file.read()\n",
    "input_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-surveillance",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <b>Tip:</b> One of the most useful things you should be doing regularly in python is checking the type of your variables. Many of your problems will be solved by knowing the variable type.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-driver",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-gazette",
   "metadata": {},
   "source": [
    "Instead of loading the file as one large string, you can read it line by line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open(\"input.txt\", 'r')\n",
    "\n",
    "print(input_file.readline())\n",
    "\n",
    "print(\"This is the next line:\")\n",
    "\n",
    "print(input_file.readline())\n",
    "\n",
    "input_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-covering",
   "metadata": {},
   "source": [
    "Or, if you want to loop over the whole file, you can use the file object as an _iterable_ (i.e., throw it in a `for` loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open(\"input.txt\", 'r')\n",
    "\n",
    "for i, line in enumerate(input_file):\n",
    "    print(\"This is line %i: %s\" % (i, line))\n",
    "    \n",
    "input_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-appearance",
   "metadata": {},
   "source": [
    "**Question**: What is the enumerate function doing here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-research",
   "metadata": {},
   "source": [
    "#### Writing a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open(\"output.txt\", 'w')\n",
    "\n",
    "output_file.write(\"This is my output file\")\n",
    "output_file.write(\"\\nThis is its second line\")\n",
    "\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong Way:\n",
    "\n",
    "output_file = open(\"output.txt\", 'w')\n",
    "\n",
    "output_file.write(\"This will overwrite the file\")\n",
    "\n",
    "output_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Right Way:\n",
    "\n",
    "output_file = open(\"output.txt\", 'a')\n",
    "\n",
    "output_file.write(\"\\nThis will append to the file\")\n",
    "\n",
    "output_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-village",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "1. Write plain text file that contains a 20-30 word bio of yourself. \n",
    "2. Read in the plain text file, and using string functions, create a Python List of strings containing each individual word from your bio. \n",
    "3. Determine the total number of words in your bio. Also, determine the number of _unique_ words in your bio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-local",
   "metadata": {},
   "source": [
    "## Reading and Writing to NumPy Arrays\n",
    "* Remembering the basics of Numpy Arrays (dimensionality, propogations)\n",
    "* Loading in from a text file (tab-separated, comma-separated)\n",
    "* Saving and Loading as Numpy Files (`.npy`, `.npz`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-password",
   "metadata": {},
   "source": [
    "Let's make the most basic of Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Simplest of Arrays\n",
    "new_array = np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-reconstruction",
   "metadata": {},
   "source": [
    "Every numpy array has a certain number of properties that you should always check. They are the number of dimension (`ndim`), number of total elements (`size`), the length of each dimension (`shape`), and the variable type (`dtype`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Dimensions: %i\" % new_array.ndim)\n",
    "print(\"Number of Elements: %i\" % new_array.size)\n",
    "print(\"Shape of Array: %s\" % str(new_array.shape))\n",
    "print(\"Data Type: %s\" % new_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_array = np.linspace(0, 5, 20)\n",
    "\n",
    "print(\"Number of Dimensions: %i\" % second_array.ndim)\n",
    "print(\"Number of Elements: %i\" % second_array.size)\n",
    "print(\"Shape of Array: %s\" % str(second_array.shape))\n",
    "print(\"Data Type: %s\" % second_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_array = np.ones((10, 5))\n",
    "\n",
    "print(\"Number of Dimensions: %i\" % third_array.ndim)\n",
    "print(\"Number of Elements: %i\" % third_array.size)\n",
    "print(\"Shape of Array: %s\" % str(third_array.shape))\n",
    "print(\"Data Type: %s\" % third_array.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-membership",
   "metadata": {},
   "source": [
    "When doing a mathematical operation on numpy arrays, it will try to perform the operation element-wise. However, if the shapes of the elements work out, it will perform it across rows or columns. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-vampire",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array([1, 2, 3, 4, 5]) * third_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-pittsburgh",
   "metadata": {},
   "source": [
    "However, you'll need to make sure the axes line up. Otherwise, it'll throw an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This won't work\n",
    "np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) * third_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-speaker",
   "metadata": {},
   "source": [
    "Here, it's trying to line up the array with size 10 with the second dimension of `third_array`, which is of length 5. Hence they don't work. However, you can `reshape` the array here to make it a 2-D array where the second dimension is just length 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-sherman",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reshaping the array so that it's two dimensions, with length 1 on the second dimension\n",
    "\n",
    "reshaped_array = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)\n",
    "print(reshaped_array.shape)\n",
    "\n",
    "reshaped_array * third_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-elite",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <b>Tip:</b> In reshapes, you can use the number \"-1\" to indicate that you want Python to automatically calculate how long this particular axis should be. Note, you can only do this for one axis at a time in a reshape.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-hartford",
   "metadata": {},
   "source": [
    "Why don't we try to read in a structured plain text file? If everything is perfect, you can use the `loadtxt` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in simple file: \n",
    "\n",
    "lots_of_numbers = np.loadtxt(\"lots_of_numbers.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "lots_of_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-cruise",
   "metadata": {},
   "source": [
    "However, for more complicated files, this doesn't work. Take a look at the file \"more_numbers.txt\" and try to determine why this doesn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in more complicated file:\n",
    "\n",
    "# This won't work\n",
    "more_numbers = np.loadtxt(\"more_numbers.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-sapphire",
   "metadata": {},
   "source": [
    "But you can handle these kinds of files with the `genfromtxt`function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_numbers = np.genfromtxt(\"more_numbers.txt\", missing_values=\"null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-algorithm",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "more_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-diary",
   "metadata": {},
   "source": [
    "However, Numpy Arrays have their limits. Generally, they need to be rectangular (or hyper-rectangular), and all of the same data type. So a file this will be a pain to try to load in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Values\n",
    "\n",
    "# Why doesn't this work?\n",
    "new_table = np.genfromtxt(\"more_numbers_missing_values.txt\", missing_values=\"null\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-married",
   "metadata": {},
   "source": [
    "Sometimes, you don't need a human-readable file -- in these cases, you can save a numpy array as an `npy` file. For these files, it's one array per file, but they're easily saved and loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Npy Files\n",
    "\n",
    "x1 = np.array([2.2, 3.4, 2.1, 3.5, 9.3])\n",
    "np.save(\"x1.npy\", x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x1 = np.load(\"x1.npy\")\n",
    "new_x1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-raise",
   "metadata": {},
   "source": [
    "If you want to save more than one array, you can use a Numpy Zip file (or `npz`), which treats all the variable as dictionary-like elements when you load them in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-wireless",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Npz Files\n",
    "x2 = np.array([12.3, 21, 32, np.nan])\n",
    "\n",
    "np.savez(\"another_variable.npz\", x1=x1, x2=x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_variables = np.load(\"another_variable.npz\")\n",
    "\n",
    "print(list(more_variables.keys()))\n",
    "\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-johnston",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Warning:</b> Numpy files, while easy to use, are not great for long-term storage or distribution. A file written on one computer or a specific version or Numpy/Python is not guaranteed to work on another. These are best used as intermediate saves for data that you intend to open on the same computer, relatively soon. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-handle",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "1. Create a two-dimensional and three-dimensional numpy arrays (containing random numbers), and multiply them to form a new array, and save them all as an npz file.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-intelligence",
   "metadata": {},
   "source": [
    "## Astropy Tables\n",
    "* A table versus an array\n",
    "* Columns and Rows\n",
    "* Reading in various formats\n",
    "* Saving out various formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-despite",
   "metadata": {},
   "source": [
    "Numpy Arrays have certain limitations, for instance:\n",
    "* They need to be all the same data type\n",
    "* They need to be rectangular/hyper rectangular (i.e., missing values are hard to deal with)\n",
    "* They are inherently multi-dimensional\n",
    "\n",
    "Often times, what you want to deal with is a certain number of objects that have a bunch of different properties. For this, what you'll want to use is a **Table**. Let's create an astropy style table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table = table.Table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-flexibility",
   "metadata": {},
   "source": [
    "The above table starts empty. Tables consist of **columns** which are each discrete property of the objects you're describing, and **rows** which are each discrete object. Columns are going to be dictionary-like (i.e., they use keys, and don't have an intrinsic order), and Rows are array-like (i.e., they use indicies and have an explicit order). \n",
    "\n",
    "Let's make a bunch of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table['name'] = [\"alpha\", \"beta\", \"gamma\"] \n",
    "new_table['mass'] = [2.1, 2.3, 4.2]\n",
    "new_table['temp'] = [6000, 2323, 233]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-roberts",
   "metadata": {},
   "source": [
    "One of the nice things about tables is that they're easy to look at and diagnose. Notice, in this table, we're told the data type of each column -- and each one is different. Let's add another object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table.add_row((\"delta\", 6.3, 10002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-august",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-writer",
   "metadata": {},
   "source": [
    "Let's say for these objects, I only care about the `temp` column, I can grab just that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-exhaust",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_table[\"temp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-midnight",
   "metadata": {},
   "source": [
    "Or maybe, I care about both the `mass` and `temp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-cricket",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_table[[\"mass\", \"temp\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-upper",
   "metadata": {},
   "source": [
    "And I can easily just grab the third row (remember, 0 indexing in python):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-place",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_table[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-auction",
   "metadata": {},
   "source": [
    "One of the great things that you can do with Astropy tables is that you can write them out to a bunch of different formats easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-vegetation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Saving as plain text\n",
    "\n",
    "new_table.write(\"my_astropy_table.csv\", format=\"ascii.csv\")\n",
    "\n",
    "new_table.write(\"my_fixedwidth_table.txt\", format=\"ascii.fixed_width\")\n",
    "\n",
    "new_table.write(\"my_latex_table.tex\", format=\"ascii.latex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-lucas",
   "metadata": {},
   "source": [
    "You can see all of the formats that you can read and write to here: [Formats that Astropy Tables can Read and Write](https://docs.astropy.org/en/stable/io/unified.html#built-in-readers-writers)\n",
    "\n",
    "For instance, here's an example of an [IPAC](https://irsa.ipac.caltech.edu/frontpage/) table, which comes from the NASA/IPAC Infrared Science Archive, that contains lots of data from different astronomical surveys. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening an IPAC table\n",
    "\n",
    "ipac = table.Table.read(\"ipac.tbl.txt\", format=\"ascii.ipac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-wages",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ipac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-inflation",
   "metadata": {},
   "source": [
    "### Exercise: \n",
    "\n",
    "1. Go to the [IPAC Web Interface for the WISE survey](https://irsa.ipac.caltech.edu/applications/Gator/), and using the WISE All-Sky Source Catalog and search for all the objects within 5 arcminutes around your favourite astronomical object. (Hint: The Object name field is generally smart enough to take common names of astronomical objects. You probably shouldn't choose a solar system object -- sorry, Mars lovers). \n",
    "2. Download the `ipac` formatted file of the default columns from the WISE object search, and open it in your Jupyter Notebook. \n",
    "3. Select the columns for the Object Name, the Position (RA and Dec), and `w1mpro` Magnitude, and save it to a LaTeX table. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-protest",
   "metadata": {},
   "source": [
    "## Reading and Writing to Pandas Dataframes\n",
    "* What are Pandas dataframes?\n",
    "* Making a data frame\n",
    "* Automagically reading in csv files\n",
    "* Writing out different data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-concern",
   "metadata": {},
   "source": [
    "Pandas is the primarily data analysis library, which makes dealing with tabular data _much easier_. It's used well beyond astronomy, so it is incredibly robust and feature filled. The most basic element of Pandas starts with a DataFrame. Let's make the simplest of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-swaziland",
   "metadata": {},
   "source": [
    "Like the Astropy tables, columns are dictionary-like, and rows are array-like. Let's make some columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"col1\"] = [2, 3, 4]\n",
    "df1[\"col4\"] = [-12.2, 23.1, 984.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-consultancy",
   "metadata": {},
   "source": [
    "We can even make columns using data from previous columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"col5\"] = df1[\"col4\"] ** df1[\"col1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-banks",
   "metadata": {},
   "source": [
    "And we can add new columns with completely different data types right from the start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"name\"] = [\"row1\", \"row2\", \"row3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-closing",
   "metadata": {},
   "source": [
    "To select individiual rows (or groups of rows), you can use the `iloc` property of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-peeing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.iloc[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-nepal",
   "metadata": {},
   "source": [
    "Some of the magic starts right off the bat, with reading in a file. CSVs are some of the most common files you'll encounter for distributing data. Let's open one up from a query from the Sloan Digital Sky Survey database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in a CSV file\n",
    "\n",
    "sdss_df = pd.read_csv(\"sdss_query.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-tanzania",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sdss_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-folks",
   "metadata": {},
   "source": [
    "Notice how it automatically populates the column names? It also would deal with missing data without intervention. \n",
    "\n",
    "And, as always, it's really easy to save your data out to a bunch of different formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To a CSV\n",
    "df1.to_csv(\"pd_df1.csv\")\n",
    "\n",
    "# How about to HTML?\n",
    "df1.to_html(\"pd_df1.html\")\n",
    "\n",
    "# Or maybe even Excel?\n",
    "df1.to_excel(\"pd_df1.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-twelve",
   "metadata": {},
   "source": [
    "**Note:** If the last line doesn't work, make sure you have the `openpyxl` package installed via pip "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-allowance",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "1. Save the IPAC table you created earlier from the Astropy Table section and save it as a CSV. \n",
    "2. Read it in as a Pandas Data Frame, and make a new column that is the distance of each object from the first object in the table (remember that these are celestial coordinates, and not simple Euclidean coordinates).  \n",
    "3. Save the new dataframe as an Excel file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
